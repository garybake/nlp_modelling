{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Using Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "# from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "# from nltk.stem.porter import *\n",
    "\n",
    "import spacy\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "We'll use a dataset of news articles grouped into 20 news categories - but just use 7 for this example.\n",
    "I've tried to pick groups that should have a decent seperation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    'comp.windows.x',\n",
    "    'rec.autos',\n",
    "    'rec.sport.baseball',\n",
    "    'rec.sport.hockey',\n",
    "    'sci.space',\n",
    "    'soc.religion.christian',\n",
    "    'talk.politics.guns'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets looks at an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: SHOE@PHYSICS.watstar.uwaterloo.ca (Mark Shoesmith)\n",
      "Subject: Re: Let's talk sticks...\n",
      "Lines: 35\n",
      "Organization: University of Waterloo\n",
      "\n",
      "In article <C50pt4.6CM@odin.corp.sgi.com> dptom@endor.corp.sgi.com (Tom Arnold) writes:\n",
      "\n",
      ">Okay you hockey playing fans/finatics out there. I'm looking over the wide \n",
      ">range of aluminum sticks for the first time. I've been playing with pieces\n",
      ">of lumbar that seem to weigh alot and break after a few uses, so I'm \n",
      ">thinking of changing to an aluminum shaft so when I break the blade all I \n",
      ">have to do is change it. The problem is that there is such a wide reange of\n",
      ">models and selections out there that I'm not certain which to consider. Can\n",
      ">any of you post some of your suggestions and experiences with the aluminum \n",
      ">sticks? What is the difference between models? What do you like/dislike about\n",
      ">them? And, which brands are best?\n",
      ">\n",
      ">\n",
      "\n",
      "I've had, and still have a few aluminum sticks.  I got my first when I was 15\n",
      "(a Christian), and broke the shaft halfway through the season, two years \n",
      "later.  I bought another (a Canadian) at the beginning of the next season, \n",
      "and I still have it.  I also have an Easton, that a friend was getting rid \n",
      "off, after giving up the game.  I find that Easton blades are easier to get, \n",
      "but all brands of blades are pretty well interchangeable.  Watch out for \n",
      "dried up bits of firewood, that some stores pass off as blades.  In my \n",
      "experiences, the blades of an aluminum break more often than regular sticks, \n",
      "but I've only ever broken one aluminum shaft.\n",
      "\n",
      "I like aluminum sticks.  The blades are quickly changed, even on the bench \n",
      "if you have to.  On the downside, the shaft won't break if you decide to \n",
      "impale yourself on it :-)\n",
      "\n",
      "Ciao,\n",
      "Mark S.\n",
      "\n",
      "\"This is between me and the vegetable\"   - Rick Moranis in\n",
      "                                           Little Shop of Horrors\n",
      "Mark Shoesmith\n",
      "shoe@physics.watstar.uwaterloo.ca\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train.data[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: rec.sport.hockey\n"
     ]
    }
   ],
   "source": [
    "target_newsgroup = newsgroups_test.target_names[newsgroups_train.target[6]]\n",
    "print('Group: {}'.format(target_newsgroup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4122,) (4122,)\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train.filenames.shape, newsgroups_train.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be enough rows normally. Though it is split over 7 categories which may not be enough.  \n",
    "Lets see how heavy each category is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({4: 593, 2: 597, 1: 594, 0: 593, 3: 600, 6: 546, 5: 599})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could map the keys to the category names but you can see by eye that it is a really balanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform the data to basically optimise it so the ML algorithm recieves the strongest signal. \n",
    "\n",
    "* Tokenization: Split the text into sentences and the sentences into words. Lowercase the words and remove punctuation.\n",
    "* Words that have fewer than 3 characters are removed.\n",
    "* Remove stopwords: such as the, is, at, which, and on.\n",
    "* Lemmatize: Words in third person are changed to first person and verbs in past and future tenses are changed into present.\n",
    "* Stemming: Words are reduced to their root form.\n",
    "\n",
    "Lemmatizing is a mapping of the word to its base form i.e. went -> go.  \n",
    "Stemming is more of a function on the word such as removing the 'ing' from the end of words.  \n",
    "We do the lemmatizing and then stemming in the lemma may be a totally different spelt word (going -> go is similar but went -> go has a totally different spelling).  \n",
    "The stemming can often result in a 'invalid' word such as argue -> argu which the lemmatizing wouldn't accept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't need the PoS tagger, the NER labeling or the text categorizer \n",
    "# https://spacy.io/usage/processing-pipelines\n",
    "nlp = spacy.load('en', disable=['tagger', 'ner', 'textcat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Space doesn't have a stemmer and we may not need it. Can confirm accuracy later.  \n",
    "https://github.com/explosion/spaCy/issues/327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    result = [token.lemma_.lower() for token in doc if not token.is_stop and len(token) > 3 and token.text in nlp.vocab]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'disk', 'fail', 'time', 'like', 'replace']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = 'This disk has failed many times. I would like to get it replaced.'\n",
    "proc = preprocess(doc_sample)\n",
    "print(proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "#DELETEME: NLTK output \n",
    "# ['disk', 'fail', 'time', 'like', 'replac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    result = [token.lemma_.lower() for token in text if not token.is_stop and len(token) > 3 and token.text in nlp.vocab]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_docs(docs):\n",
    "    processed = list(nlp.pipe(newsgroups_train.data))\n",
    "    \n",
    "    processed_docs = []\n",
    "\n",
    "    for doc in processed:\n",
    "        processed_docs.append(preprocess(doc))\n",
    "        \n",
    "    return processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs = nlp.pipe(newsgroups_train.data)\n",
    "processed_docs = preprocess_docs(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed = list(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess all the messages we have (in parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess(text):\n",
    "# #     doc = nlp(text)\n",
    "#     result = [token.lemma_.lower() for token in text if not token.is_stop and len(token) > 3 and token.text in nlp.vocab]\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = [token.lemma_.lower() for token in processed if not token.is_stop and len(token) > 3]\n",
    "# processed_docs = []\n",
    "\n",
    "# for doc in processed:\n",
    "#     processed_docs.append(preprocess(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multiprocessing\n",
    "# pool = multiprocessing.Pool()\n",
    "# processed_docs = list(pool.map(preprocess, newsgroups_train.data))\n",
    "# https://github.com/explosion/spaCy/issues/1839\n",
    "# processed_docs = []\n",
    "\n",
    "# for doc in newsgroups_train.data:\n",
    "#     processed_docs.append(preprocess(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['from', 'subject', 'version', 'organization', 'university', 'lines', 'please', 'real', 'life'], ['from', 'richard', 'subject', 'cards', 'list', 'distribution', 'organization', 'hewlett', 'packard', 'lines', 'count', 'interest', 'cardinal', 'mail', 'list', 'find', 'start', 'know', 'thanks', 'dick']]\n"
     ]
    }
   ],
   "source": [
    "print(processed_docs[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Bag of words\n",
    "\n",
    "A dictionary is the number of times a word appears in the training set.\n",
    "A mapping between words and their integer ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 from\n",
      "1 life\n",
      "2 lines\n",
      "3 organization\n",
      "4 please\n",
      "5 real\n",
      "6 subject\n"
     ]
    }
   ],
   "source": [
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    if k > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out tokens that appear in\n",
    "* less than 15 documents or\n",
    "* more than 10% of documents\n",
    "* after (1) and (2), keep only the first 100k most frequent tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.1, keep_n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert document (a list of words) into the bag-of-words format.  \n",
    "A list of (token_id, token_count) tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(243, 1) - driver\n"
     ]
    }
   ],
   "source": [
    "bow_doc_x = bow_corpus[10]\n",
    "bow_word_x = 3\n",
    "\n",
    "print('{} - {}'.format(\n",
    "    bow_doc_x[5],\n",
    "    dictionary[bow_doc_x[bow_word_x][0]]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the LDA Model\n",
    "(Latent Dirichlet Allocation)  \n",
    "If observations are words collected into documents, it posits that each document is a mixture of a small number of topics and that each word's presence is attributable to one of the document's topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **alpha** and **eta** are hyperparameters that affect sparsity of the document-topic (theta) and topic-word (lambda) distributions. We will let these be the default values for now(default value is `1/num_topics`)\n",
    "    - Alpha is the per document topic distribution.\n",
    "        * High alpha: Every document has a mixture of all topics(documents appear similar to each other).\n",
    "        * Low alpha: Every document has a mixture of very few topics\n",
    "\n",
    "    - Eta is the per topic word distribution.\n",
    "        * High eta: Each topic has a mixture of most words(topics appear similar to each other).\n",
    "        * Low eta: Each topic has a mixture of few words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(\n",
    "    bow_corpus,\n",
    "    num_topics=7,\n",
    "    id2word=dictionary,                                    \n",
    "    passes=10,\n",
    "    workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.009*\"weapon\" + 0.008*\"gun\" + 0.007*\"firearm\" + 0.007*\"control\" + 0.007*\"government\" + 0.006*\"file\" + 0.006*\"crime\" + 0.005*\"kill\" + 0.005*\"bill\" + 0.004*\"criminal\"'),\n",
       " (1,\n",
       "  '0.014*\"christian\" + 0.012*\"jesus\" + 0.009*\"church\" + 0.007*\"christ\" + 0.007*\"bible\" + 0.007*\"faith\" + 0.006*\"truth\" + 0.006*\"word\" + 0.006*\"reason\" + 0.005*\"life\"'),\n",
       " (2,\n",
       "  '0.017*\"space\" + 0.007*\"software\" + 0.007*\"nasa\" + 0.005*\"station\" + 0.005*\"system\" + 0.005*\"black\" + 0.005*\"shuttle\" + 0.005*\"jewish\" + 0.004*\"book\" + 0.004*\"european\"'),\n",
       " (3,\n",
       "  '0.009*\"drive\" + 0.009*\"car\" + 0.006*\"engine\" + 0.005*\"speed\" + 0.005*\"auto\" + 0.005*\"road\" + 0.004*\"light\" + 0.004*\"leave\" + 0.004*\"fire\" + 0.004*\"driver\"'),\n",
       " (4,\n",
       "  '0.017*\"space\" + 0.009*\"program\" + 0.009*\"file\" + 0.008*\"entry\" + 0.008*\"launch\" + 0.006*\"satellite\" + 0.006*\"orbit\" + 0.006*\"nasa\" + 0.006*\"moon\" + 0.005*\"system\"'),\n",
       " (5,\n",
       "  '0.012*\"player\" + 0.009*\"season\" + 0.009*\"hockey\" + 0.007*\"score\" + 0.006*\"league\" + 0.005*\"division\" + 0.005*\"goal\" + 0.005*\"baseball\" + 0.004*\"toronto\" + 0.004*\"run\"'),\n",
       " (6,\n",
       "  '0.023*\"window\" + 0.012*\"server\" + 0.011*\"file\" + 0.009*\"application\" + 0.008*\"program\" + 0.008*\"available\" + 0.008*\"widget\" + 0.007*\"version\" + 0.007*\"include\" + 0.007*\"system\"')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_map = {\n",
    "    1: 'comp.windows.x',\n",
    "    3: 'rec.autos',\n",
    "    6: 'rec.sport.baseball',\n",
    "    5: 'rec.sport.hockey',\n",
    "    4: 'sci.space',\n",
    "    1: 'soc.religion.christian',\n",
    "    0: 'talk.politics.guns'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing model on unseen document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: eggertj@moses.ll.mit.edu (Jim Eggert x6127 g41)\n",
      "Subject: Re: Robin Lane Fox's _The Unauthorized Version_?\n",
      "Reply-To: eggertj@ll.mit.edu\n",
      "Organization: MIT Lincoln Lab - Group 41\n",
      "Lines: 19\n",
      "\n",
      "In article <May.7.01.09.39.1993.14550@athos.rutgers.edu> iscleekk@nuscc.nus.sg (LEE KOK KIONG JAMES) writes:\n",
      "|   mpaul@unl.edu (marxhausen paul) writes:\n",
      "|   > My mom passed along a lengthy review she clipped regarding Robin Lane\n",
      "|   > Fox's book _The Unauthorized Version: Truth and Fiction in the Bible_,\n",
      "|...\n",
      "|   I've read the book. Some parts were quite typical regarding its\n",
      "|   criticism of the bible as an inaccurate historical document,\n",
      "|   alt.altheism, etc carries typical responses, but not as vociferous as\n",
      "|   a.a. It does give an insight into how these historian (is he one... I \n",
      "|   don't have any biodata on him) work. I've not been able to understand/\n",
      "|   appreciate some of the arguments, something like, it mentions certain \n",
      "|   events, so it has to be after that event, and so on. \n",
      "\n",
      "Robin Lane Fox is a historian and a gardener.  He has written several\n",
      "history books, perhaps a recent one you might remember is \"The Search\n",
      "for Alexander\".  He has also written or edited several books on\n",
      "gardening.\n",
      "--\n",
      "=Jim  eggertj@ll.mit.edu (Jim Eggert)\n",
      "\n",
      "5\n",
      "soc.religion.christian\n"
     ]
    }
   ],
   "source": [
    "num = 2\n",
    "unseen_document = newsgroups_test.data[num]\n",
    "print(unseen_document)\n",
    "print(newsgroups_test.target[num])\n",
    "print(newsgroups_test.target_names[newsgroups_test.target[num]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing step for the unseen document\n",
    "# processed_docs = preprocess_docs(newsgroups_train.data)\n",
    "bow_vector = dictionary.doc2bow(preprocess_docs([unseen_document]))\n",
    "pred = sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicts soc.religion.christian with a probability of 50.96%\n"
     ]
    }
   ],
   "source": [
    "print('predicts {} with a probability of {:.2f}%'.format(categories_map[pred[0][0]], pred[0][1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model correctly classifies the unseen document with 'x'% probability to the X category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "pool = multiprocessing.Pool()\n",
    "test_processed_docs = list(pool.map(preprocess, newsgroups_test.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bow_corpus = [dictionary.doc2bow(doc) for doc in test_processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = newsgroups_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp.windows.x',\n",
       " 'rec.autos',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_test.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i, doc in enumerate(test_bow_corpus):\n",
    "    pred_all = sorted(lda_model[doc], key=lambda tup: -1*tup[1])\n",
    "    pred_cat = categories_map[pred_all[0][0]]\n",
    "    y_pred.append(newsgroups_test.target_names.index(pred_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is the proportion of correct predictions of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6985052861830113"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a confusion matrix \n",
    "from sklearn.metrics import confusion_matrix \n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_pred ->, y_true \\/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[362,  11,   0,   8,  12,   2,   0],\n",
       "       [  5, 317,   0,  33,  11,  27,   3],\n",
       "       [  6,   8,   0, 356,   5,  18,   4],\n",
       "       [  0,   7,   0, 382,   2,   6,   2],\n",
       "       [  5,  13,   0,   3, 325,  25,  23],\n",
       "       [  3,   3,   0,   3,   5, 381,   3],\n",
       "       [  2, 174,   0,   5,   2,  32, 149]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyLDAvis.gensim\n",
    "# pyLDAvis.enable_notebook()\n",
    "# prepared = pyLDAvis.gensim.prepare(lda_model, bow_corpus, dictionary)\n",
    "# pyLDAvis.show(prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
